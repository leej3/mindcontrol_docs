{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path('/data/Dnude/')\n",
    "%pwd\n",
    "%cd {project_dir}\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_version = \"2018_05_09\"\n",
    "scripts_dir  = Path('bids_work/mindcontrol_docs/defacing_files/')\n",
    "sing_image = scripts_dir.joinpath('pydeface_v2-2018-01-29-e2252feba083.img')\n",
    "swarm_dict_pkld = scripts_dir.joinpath('swarm_dict.pklz')\n",
    "\n",
    "if 'swarm_dict' in locals():\n",
    "    swarm_dict.to_pickle(swarm_dict_pkld)\n",
    "elif swarm_dict_pkld.exists():\n",
    "    swarm_dict = pd.read_pickle(swarm_dict_pkld)\n",
    "else:\n",
    "    swarm_dict = pd.Series({})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydeface docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a docker image for pydeface for reproducibility. Building image with neurodocker."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash \n",
    "docker pull kaczmarj/neurodocker:master\n",
    "docker run --rm kaczmarj/neurodocker:master generate \\\n",
    "--base debian:stretch --pkg-manager apt \\\n",
    "--fsl version=5.0.10 \\\n",
    "--user root \\\n",
    "--install git vim \\\n",
    "--user neuro \\\n",
    "--miniconda env_name=neuro \\\n",
    "            conda_opts=\"--channel conda-forge\" \\\n",
    "            conda_install=\"python nipype nibabel\" \\\n",
    "            pip_install=\"git+git://github.com/leej3/pydeface.git\" \\\n",
    "            activate=true \\\n",
    "--workdir /home/neuro \\\n",
    "--no-check-urls > /data/SharedData/7t_100runs/analysis_files/defacing_files/dockerfiles/generated-full_v2.Dockerfile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "### this was built for 7t, and v2 was built in that directory too\n",
    "cd /data/SharedData/7t_100runs/analysis_files/defacing_files/dockerfiles\n",
    "docker build -t pydeface_v2 -f generated-full_v2.Dockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The abover makes the pydeface docker container that is used below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup to deface all brains (singularity image actually used though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_scans = scripts_dir.joinpath('faced_scans')\n",
    "if not original_scans.exists():\n",
    "    original_scans.mkdir()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ipparallel to speed things up a little:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids.grabbids import BIDSLayout\n",
    "project_root = '/data/Dnude/bids_work/mindcontrol_docs/linked_bids/'\n",
    "layout = BIDSLayout(project_root)\n",
    "layout_der = BIDSLayout(Path(project_root,'derivatives'))\n",
    "df_bids = layout.as_data_frame()\n",
    "df_scans = df_bids.loc[df_bids.path.str.contains('nii.gz'),:]\n",
    "df_scans = df_scans.query('type !=\"defaced\"').query('modality == \"anat\"')\n",
    "df_scans['orig_path'] = df_bids.path.apply(lambda x: Path(x).resolve().as_posix().replace('/gpfs/gsfs4/users','/data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_scans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defacing step: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_scans))\n",
    "df_scans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the project directory below\n",
    "def make_deface_cmd(nifti_path,datadir,container_image='pydeface_v2',dev=False,singularity=True,other_images=[],template=None):\n",
    "    from pathlib import Path\n",
    "    datadir = Path(datadir)\n",
    "    try:\n",
    "        nifti_path = Path(nifti_path).relative_to(datadir)\n",
    "    except ValueError:\n",
    "        nifti_path = Path(nifti_path)\n",
    "    container_image = Path(container_image).as_posix()\n",
    "    cmd = \"docker run -v \" +  datadir.absolute().as_posix() + ':/mnt'\n",
    "    if dev:\n",
    "        cmd += ' -v /data/rodgersleejg/pydeface/pydeface/:/opt/conda/envs/neuro/lib/python3.6/site-packages/pydeface/'\n",
    "        \n",
    "    cmd += ' --rm ' + container_image + \\\n",
    "    \" bash -c 'source activate neuro; /neurodocker/startup.sh pydeface\"\n",
    "    \n",
    "    if other_images:\n",
    "        other_images = [Path(p).as_posix() for p in other_images]\n",
    "        cmd += \" --deface_others_with_base \" + ' '.join(other_images)\n",
    "        \n",
    "    if template:\n",
    "        cmd += '--template ' + template \n",
    "\n",
    "    cmd += \" --force --verbose\"  + \\\n",
    "    \" \" + Path('/mnt',nifti_path).as_posix() + \"'\"\n",
    "    \n",
    "    \n",
    "    if singularity:\n",
    "        cmd = cmd.replace('docker run','module load singularity;singularity exec -H /home/rodgersleejg/temp_for_singularity').replace(' --rm','').replace(' -v ', ' -B ',)\n",
    "    return cmd\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    print(cmd)\n",
    "    output = !{cmd}\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scans['cmd'] = df_scans.apply(lambda row:make_deface_cmd(row.orig_path,project_dir,container_image=sing_image,dev=False,singularity=True),axis = 1)\n",
    "df_scans.head().cmd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!module load singularity;singularity exec -H /home/rodgersleejg/temp_for_singularity -B /data/Dnude:/mnt bids_work/mindcontrol_docs/defacing_files/pydeface_v2-2018-01-29-e2252feba083.img bash -c 'source activate neuro; /neurodocker/startup.sh pydeface --force --verbose /mnt/bids_work/mindcontrol_docs/mindcontrol_base_dir/freesurfer/sub-0505_ses-01/T1.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_dict['deface'] = scripts_dir.joinpath('deface%s.cmd'%analysis_version)\n",
    "swarm_dict['deface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_dict['deface'].write_text('\\n'.join(df_scans.cmd[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_dict['deface'].read_text().splitlines()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f {swarm_dict['deface']}  -g 4 --logdir swarm_log --partition quick,nimh -p 2 -b 4 --time 00:10:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backup_dest(backup_dir,scan_path):\n",
    "    return backup_dir.joinpath(Path(scan_path).parent.name + '_T1.nii.gz')\n",
    "    \n",
    "df_paths = (df_scans.assign(\n",
    "    original_path = lambda df: df.orig_path).\n",
    "            assign(\n",
    "                backup_path = lambda df:\n",
    "                df.original_path.apply(lambda x:\n",
    "                           get_backup_dest(backup_dir = original_scans,scan_path = x))\n",
    "))\n",
    "\n",
    "assert(0== df_paths.duplicated('backup_path').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup original scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_scans(df_row,source=None,destination=None,overwrite=False):\n",
    "    \"\"\"\n",
    "    Move scans.\n",
    "    Input is a pandas dataframe row containing paths.\n",
    "    Source and destination column are specified\n",
    "    \"\"\"\n",
    "    source_file = Path(df_row[source])\n",
    "    target_file = Path(df_row[destination])\n",
    "#     print(\"source\",source_file)\n",
    "#     print(\"target\",target_file)\n",
    "    if not source_file.exists():\n",
    "        print(f'{source_file} does not exist')\n",
    "    elif target_file.exists() and not overwrite:\n",
    "        print(f'{target_file} exists. Must set overwrite argument to True')\n",
    "    else:\n",
    "        pass\n",
    "        stdout = %mv {df_row[source]} {df_row[destination]} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths.loc[:2,:].apply(move_scans, source='original_path', destination='backup_path', axis=1);\n",
    "# df_paths.apply(move_scans, source='backup_path', destination='original_path', axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths.loc[:2,:].backup_path.apply(lambda x: Path(x).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths.loc[:2,:].original_path.apply(lambda x: Path(x).exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths.loc[3:,:].apply(move_scans, source='original_path', destination='backup_path', axis=1);\n",
    "# df_paths.apply(move_scans, source='backup_path', destination='original_path', axis=1);\n",
    "# df_paths.query('path.str.contains(\"derivatives\")').apply(move_scans, source='backup_path', destination='original_path', axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scans are present:\n",
    "# for f in df_paths.backup_path:\n",
    "#     !ls {f}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename defaced scans for BIDS compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths['defaced_path'] = (df_paths.\n",
    "                             original_path.\n",
    "                             apply(\n",
    "                                 lambda x:\n",
    "                                 Path(Path(x).as_posix().split('.')[0] + '_defaced.nii.gz'))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_paths.loc[df_paths.backup_path.apply(lambda x: not Path(x).exists()),:]\n",
    "df_paths.loc[df_paths.defaced_path.apply(lambda x: not Path(x).exists()),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths\n",
    "df_paths.apply(move_scans, source='defaced_path', destination='original_path', axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_paths\n",
    "# df_paths.loc[1:2,:].apply(move_scans, source='defaced_path', destination='original_path', axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scans are present:\n",
    "# for f in df_paths.original_path:\n",
    "#     !ls {f}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
